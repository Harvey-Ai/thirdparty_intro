thirdparty_intro
================

## Google 开源库

* [zh-google-styleguide](http://zh-google-styleguide.readthedocs.org/en/latest/) - Google 开源项目风格指南.
* [protobuf](https://code.google.com/p/protobuf/) - Protocol Buffers - Google's data interchange format.
* [gflags](https://code.google.com/p/gflags/) - Commandline flags module for C++. 
* [glog](https://code.google.com/p/google-glog/) - Logging library for C++.  
* [gtest](https://code.google.com/p/googletest/) - Google C++ Testing Framework.
* [googlemock](https://code.google.com/p/googlemock/) - Google C++ Mocking Framework.
* [leveldb](http://code.google.com/p/leveldb/) - A fast and lightweight key/value database library by Google.
  [cpy-leveldb](https://github.com/carlopires/cpy-leveldb) - Python bindings for LevelDB using leveldb c api.
* [The Chromium Projects](http://www.chromium.org/) - The Chromium projects include Chromium and Chromium OS, the open-source projects behind the Google Chrome browser and Google Chrome OS, respectively. 

## C++ base 库

* [toft](https://github.com/chen3feng/toft) - C++ Base Library for Linux server side development.
  [thirdparty](https://github.com/chen3feng/thirdparty) - Put thirdparty library here for toft ant foxy.
  [chen3feng](https://github.com/chen3feng)
* [folly](https://github.com/facebook/folly) - Folly is an open-source C++ library developed and used at Facebook.

## 算法和数据结构

* [darts-clone](https://code.google.com/p/darts-clone/) - A clone of the Darts (Double-ARray Trie System).
* [Darts](http://chasen.org/~taku/software/darts/) - Double-ARray Trie System. [中文翻译文档](http://www.52nlp.cn/darts-double-array-trie-system-%E7%BF%BB%E8%AF%91%E6%96%87%E6%A1%A3)
* [sparsehash](https://code.google.com/p/sparsehash/?redir=1) - An extremely memory-efficient hash_map implementation。
* [cityhash](https://code.google.com/p/cityhash/) - The CityHash family of hash functions.
* [stringencoders](https://code.google.com/p/stringencoders/) - A collection of high performance c-string transformations, frequently 2x faster than standard implementations (if they exist at all).
* [Numpy](http://www.numpy.org/) - NumPy is the fundamental package for scientific computing with Python.

## 自然语言处理库

* [NLTK](https://github.com/nltk/nltk) - NLTK -- the Natural Language Toolkit -- is a suite of open source Python modules, data sets and tutorials supporting research and development in Natural Language Processing.
  [NLTK Book](https://github.com/nltk/nltk_book)
* [jieba](https://github.com/fxsjy/jieba) - 结巴中文分词.
* [gensim](https://github.com/piskvorky/gensim) - Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.
* [LTP](http://www.ltp-cloud.com/) - 语言技术平台（Language Technology Platform，LTP）是哈工大社会计算与信息检索研究中心历时十年研制的一整套开放中文自然语言处理系统。
* [Stanford CoreNLP](http://nlp.stanford.edu/software/corenlp.shtml) - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize dates, times, and numeric quantities, and mark up the structure of sentences in terms of phrases and word dependencies, and indicate which noun phrases refer to the same entities. 
* [openNLP](http://opennlp.apache.org/) - The Apache OpenNLP library is a machine learning based toolkit for the processing of natural language text.
* [SRILM](http://www.speech.sri.com/projects/srilm/) - SRILM is a toolkit for building and applying statistical language models (LMs), primarily for use in speech recognition, statistical tagging and segmentation, and machine translation. 
* [IRSTLM](http://hlt.fbk.eu/en/irstlm) - The IRST Language Modeling Toolkit features algorithms and data structures suitable to estimate, store, and access very large LMs. 
* [KenLM](http://kheafield.com/code/kenlm/estimation/) - KenLM estimates unpruned language models with modified Kneser-Ney smoothing.
* [Moses](http://www.statmt.org/moses/) - Moses is a statistical machine translation system that allows you to automatically train translation models for any language pair.
* [GIZA++](https://code.google.com/p/giza-pp/) - GIZA++ is a statical machine translation toolkit that is used to train IBM Models 1-5 and an HMM word alignment model.
* [genius](https://github.com/duanhongyi/genius) - genius中文分词，是基于crf条件随机场的分组件.
* [sego](https://github.com/huichen/sego) - Go中文分词.
* [pinyin](https://github.com/huichen/pinyin) - Go语言汉字转拼音工具.
* [ReVerb](https://github.com/knowitall/reverb/) - ReVerb is a program that automatically identifies and extracts binary relationships from English sentences. ReVerb is designed for Web-scale information extraction, where the target relations cannot be specified in advance and speed is important.

## 信息检索库

* [Lemur](http://www.lemurproject.org/) - The Lemur Project develops search engines, browser toolbars, text analysis tools, and data resources that support research and development of information retrieval and text mining software. 
* [Lucene](http://lucene.apache.org/) - The Apache Lucene project develops open-source search software.
* [gensim](https://github.com/piskvorky/gensim) - Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.
* [wukong](https://github.com/huichen/wukong) - 悟空全文搜索引擎.
* [Scrapy](http://scrapy.org) - a fast high-level screen scraping and web crawling framework for Python. 
* [distribute_crawler](https://github.com/gnemoug/distribute_crawler) - 使用scrapy,redis, mongodb,graphite实现的一个分布式网络爬虫,底层存储mongodb集群,分布式使用redis实现, 爬虫状态显示使用graphite实现。

## 机器学习库

* [libsvm](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) - A Library for Support Vector Machines.
* [liblinear](http://www.csie.ntu.edu.tw/~cjlin/liblinear/) - A Library for Large Linear Classification.
* [RankLib](http://people.cs.umass.edu/~vdang/ranklib.html) - RankLib is a library of learning to rank algorithms. 
* [svmlight](http://www.cs.cornell.edu/people/tj/svm_light/) - SVMlight is an implementation of Support Vector Machines (SVMs) in C.
* [plda](http://code.google.com/p/plda/) - A parallel C++ implementation of fast Gibbs sampling of Latent Dirichlet Allocation
* [GibbsLDA++](http://gibbslda.sourceforge.net/) - A C/C++ implementation of Latent Dirichlet Allocation (LDA) using Gibbs Sampling technique for parameter estimation and inference.
* [Yahoo_LDA](https://github.com/shravanmn/Yahoo_LDA) - Yahoo!'s topic modelling framework using Latent Dirichlet Allocation
* [word2vec](https://code.google.com/p/word2vec/) - Tool for computing continuous distributed representations of words.
* [Maximum Entropy Modeling Toolkit for Python and C++](https://github.com/lzhang10/maxent) - This package provides a (Conditional) Maximum Entropy Modeling Toolkit for Python and C++. 
* [maxent](http://www.nactem.ac.uk/tsuruoka/maxent/) - A simple C++ library for maximum entropy classification.
* [easyME](https://github.com/nicyun/easyME) - This is a simple implementation of Maximum Entropy model. Algorithms implemented include: GIS, SCGIS, LBFGS, Gaussian smoothing and Exponential smoothing.
* [libLBFGS](http://www.chokkan.org/software/liblbfgs/) - This library is a C port of the implementation of Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) method written by Jorge Nocedal. 
* [OWL-QN](http://research.microsoft.com/en-us/downloads/b1eb1016-1738-4bd5-83a9-370c9d498a03/) - The Orthant-Wise Limited-memory Quasi-Newton algorithm (OWL-QN) is a numerical optimization procedure for finding the optimum of an objective of the form {smooth function} plus {L1-norm of the parameters}. It has been used for training log-linear models (such as logistic regression) with L1-regularization.
* [CRF++](http://crfpp.googlecode.com/svn/trunk/doc/index.html?source=navbar) - CRF++ is a simple, customizable, and open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data. CRF++ is designed for generic purpose and will be applied to a variety of NLP tasks, such as Named Entity Recognition, Information Extraction and Text Chunking.
* [CRFsuite](http://www.chokkan.org/software/crfsuite/) - A fast implementation of Conditional Random Fields (CRFs).
* [Wapiti](http://wapiti.limsi.fr/) - Wapiti is a very fast toolkit for segmenting and labeling sequences with discriminative models. It is based on maxent models, maximum entropy Markov models and linear-chain CRF and proposes various optimization and regularization methods to improve both the computational complexity and the prediction performance of standard models.
* [sofia-ml](http://code.google.com/p/sofia-ml/) - Suite of Fast Incremental Algorithms for Machine Learning. Includes methods for learning classification and ranking models, using Pegasos SVM, SGD-SVM, ROMMA, Passive-Aggressive Perceptron, Perceptron with Margins, and Logistic Regression.
* [mahout](http://mahout.apache.org/) - The Apache Mahout machine learning library's goal is to build scalable machine learning libraries.
* [MLTK](https://github.com/fandywang/mltk) - MLTK -- the Machine Learning Toolkit -- is a suite of C++ open source modules of Machine Learning. 
* [FP-growth](https://github.com/enaeseth/python-fp-growth) - An implementation of the FP-growth algorithm in pure Python.

* [MLcomp](http://mlcomp.org/) - MLcomp is a free website for objectively comparing machine learning programs across various datasets for multiple problem domains.

## 数据交换协议

* [protobuf](https://code.google.com/p/protobuf/) - Protocol Buffers - Google's data interchange format.
* [jsoncpp](http://jsoncpp.sourceforge.net/) - JSON data format manipulation library.
* [tinyxml2](http://www.grinninglizard.com/tinyxml2/index.html) - TinyXML-2 is a simple, small, efficient, C++ XML parser that can be easily integrating into other programs.
* [thrift](http://thrift.apache.org/) - The Apache Thrift software framework, for scalable cross-language services development, combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages.

## 数据库

* [MySQL++](http://tangentsoft.net/mysql++/) - MySQL++ is a C++ wrapper for MySQL’s C API.
* [MongodDB](http://www.mongodb.org/) - MongoDB (from "humongous") is an open-source document database, and the leading NoSQL database. Written in C++.
* [memcached](http://memcached.org/) - Free & open source, high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load.
* [leveldb](http://code.google.com/p/leveldb/) - A fast and lightweight key/value database library by Google.
* [SSDB](https://github.com/ideawu/ssdb) - A fast NoSQL database server with zset data type, an alternative to Redis. SSDB is a high performace key-value(key-string, key-zset, key-hashmap) NoSQL persistent storage server, using Google LevelDB as storage engine. SSDB is stable, production-ready and is widely used by many Internet companies such as QIHU 360.
* [fatcache](https://github.com/twitter/fatcache) - Memcache on SSD. Think of fatcache as a cache for your big data.

## 网络编程

* [thrift](http://thrift.apache.org/) - The Apache Thrift software framework, for scalable cross-language services development, combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages.
* [server1](https://code.google.com/p/server1/) - a c++ network server/client framework.
* [muduo-protorpc](https://github.com/chenshuo/muduo-protorpc) - Google Prorobuf RPC based on Muduo.

## Web 开发

* [Flask](http://flask.pocoo.org/) - Flask is a microframework for Python based on Werkzeug and Jinja2.  It's intended for getting started very quickly and was developed with best intentions in mind.
  [中文docs](https://github.com/dormouse/Flask_Docs_ZhCn)
* [Bootstrap](http://getbootstrap.com/) - Sleek, intuitive, and powerful front-end framework for faster and easier web development.
* [Django](https://www.djangoproject.com/) - Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design.

## 分布式计算

* [Hadoop](http://hadoop.apache.org/) - The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.
* [ZooKeeper](http://zookeeper.apache.org/) - ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. 
* [Storm](http://storm-project.net/) - Distributed and fault-tolerant realtime computation.
  [Storm 维基](https://github.com/nathanmarz/storm/wiki) - 提供了有关 Storm、它的理论基础的大量优秀文档，以及有关获取 Storm 和设置新项目的各种教程。您还将找到一些有关 Storm 的许多方面的实用文档，包括 Storm 在本地模式、集群模式和在 Amazon 上的使用。
  GitHub 上提供了 Storm 的一个 [thorough class tree exists](http://nathanmarz.github.io/storm/doc/index.html)，详细介绍了 Storm 的类和接口。
  [使用 Twitter Storm 处理实时的大数据](http://www.ibm.com/developerworks/cn/opensource/os-twitterstorm/) - 流式处理大数据简介 简介： Storm 是一个开源的、大数据处理系统，与其他系统不同，它旨在用于分布式实时处理且与语言无关。了解 Twitter Storm、它的架构，以及批处理和流式处理解决方案的发展形势。
  [Storm 入门教程](http://blog.linezing.com/category/storm-quick-start?spm=0.0.0.0.oU9c5c) - 来自[量子恒道官方博客](http://blog.linezing.com/?spm=0.0.0.0.5QdtJI)
  [storm-starter](https://github.com/nathanmarz/storm-starter) - Learn to use Storm!
* [Spark](http://spark.incubator.apache.org/) - Lightning-Fast Cluster Computing.
* [Puppet](http://puppetlabs.com/puppet/what-is-puppet) - Puppet is IT automation software that helps system administrators manage infrastructure throughout its lifecycle, from provisioning and configuration to orchestration and reporting. Using Puppet, you can easily automate repetitive tasks, quickly deploy critical applications, and proactively manage change, scaling from 10s of servers to 1000s, on-premise or in the cloud.
* [Giraph](http://giraph.apache.org/) - Large-scale graph processing on Hadoop.
* [Skynet](https://github.com/skynetservices/skynet) - Skynet is a framework for distributed services in Go.
* [Kafka](http://kafka.apache.org/) - 分布式消息队列系统，A high-throughput distributed messaging system. 
  [Kafka Clients](https://cwiki.apache.org/confluence/display/KAFKA/Clients)

## 正则表达式

* [re2](http://code.google.com/p/re2/) - an efficient, principled regular expression library.

## 编译工具

* [SCons](http://www.scons.org/) - SCons is an Open Source software construction tool—that is, a next-generation build tool. Think of SCons as an improved, cross-platform substitute for the classic Make utility with integrated functionality similar to autoconf/automake and compiler caches such as ccache. In short, SCons is an easier, more reliable and faster way to build software.
* [CMake](http://www.cmake.org/) - the cross-platform, open-source build system. 
* [blade](http://code.tencent.com/projects/blade/) - Blade is designed to be a modernize building system.
* [bobo](https://github.com/bin3/bobo) - Bobo is an easy to use building tool inspired by blade.

## Code Review

* [rietveld](http://code.google.com/p/rietveld/) - Code Review, hosted on Google App Engine.
* [Review Board](http://www.reviewboard.org/) - Take the pain out of code review.

## vim

* [spf13-vim](http://vim.spf13.com/) - spf13-vim is a distribution of vim plugins and resources for Vim, GVim and MacVim.  It is a completely cross platform distribution that stays true to the feel of vim while providing modern features like a plugin management system, autocomplete, tags and tons more.
* [Maximum Awesome](https://github.com/square/maximum-awesome) - Config files for vim and tmux, lovingly tended by a small subculture of peace-loving hippies. Built for Mac OS X.
* [VimClojure](https://github.com/vim-scripts/VimClojure) - A filetype, syntax and indent plugin for Clojure.

## golang base 库

* [glog](https://github.com/golang/glog) - Leveled execution logs for Go. 
* [groupcache](https://github.com/golang/groupcache) - groupcache is a caching and cache-filling library, intended as a replacement for memcached in many cases.

## Go 学习

* [Go语言资料收集](https://github.com/wonderfo/wonderfogo/wiki) - 

## Python 学习

* [pycrumbs](https://github.com/kirang89/pycrumbs) - Bits and Bytes of Python from the Internet.
